{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c4da947",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "We're going to do a visual comparison of the ProtHash and ESMC embeddings as a sanity check. We're expecting that, if ProtHash successfully learned from its ESMC teacher, the two embeddings will be nearly identical in terms of their 2D plots. Now it's not exactly comparing apples to apples when you have to take two high-dimensional embeddings of likely different dimensions and reduce them both down to only two dimensions - but this is just a sanity check.\n",
    "\n",
    "Let's kick this party off by defining some configuration variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb3f0812",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_sequence_length=1\n",
    "max_sequence_length=2048\n",
    "num_samples=2000\n",
    "batch_size=8\n",
    "\n",
    "teacher_model_name=\"esmc_600m\"\n",
    "\n",
    "checkpoint_path=\"checkpoints/checkpoint.pt\"\n",
    "\n",
    "device=\"cuda\"  # Can be \"cuda\", \"mps\", etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a2d7588",
   "metadata": {},
   "source": [
    "Then, we'll load the ESM protein sequence tokenizer and the SwissProt dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161ab08a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from esm.tokenization import EsmSequenceTokenizer\n",
    "\n",
    "from data import SwissProt\n",
    "\n",
    "from torch.utils.data import Subset, DataLoader\n",
    "\n",
    "tokenizer = EsmSequenceTokenizer()\n",
    "\n",
    "dataset = SwissProt(\n",
    "    tokenizer=tokenizer,\n",
    "    min_sequence_length=min_sequence_length,\n",
    "    max_sequence_length=max_sequence_length,\n",
    ")\n",
    "\n",
    "dataset = Subset(dataset, range(num_samples))\n",
    "\n",
    "dataloader = DataLoader(\n",
    "    dataset, batch_size=batch_size, shuffle=False, collate_fn=dataset.dataset.collate_pad_right\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b5f23b7",
   "metadata": {},
   "source": [
    "Next we'll load the teacher model, ESMC, from its pretrained weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d3050e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from esm.models.esmc import ESMC\n",
    "\n",
    "teacher = ESMC.from_pretrained(teacher_model_name)\n",
    "\n",
    "teacher = teacher.to(device)\n",
    "\n",
    "teacher.eval()\n",
    "\n",
    "print(\"Teacher model loaded successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ed99f5",
   "metadata": {},
   "source": [
    "Now you've made it this far it's time for some fun. Let's go down and dirty and load one of our ProtHash model checkpoints into memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc57ffc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from src.prothash.model import ProtHash\n",
    "\n",
    "checkpoint = torch.load(checkpoint_path, map_location=\"cpu\", weights_only=True)\n",
    "\n",
    "student = ProtHash(**checkpoint[\"model_args\"])\n",
    "\n",
    "student.add_adapter_head(checkpoint[\"teacher_embedding_dimensions\"])\n",
    "\n",
    "student.load_state_dict(checkpoint[\"model\"])\n",
    "\n",
    "student.remove_adapter_head()\n",
    "\n",
    "student = student.to(device)\n",
    "\n",
    "student.eval()\n",
    "\n",
    "print(\"Model checkpoint loaded successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f3ea80e",
   "metadata": {},
   "source": [
    "You've made it this far there's no turning back. It's literally life or death from here on out. Next we'll be embedding a subset of the SwissProt dataset with both models. I'll know if you turned back from here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c81d554c",
   "metadata": {},
   "outputs": [],
   "source": [
    "student_embeddings = []\n",
    "teacher_embeddings = []\n",
    "\n",
    "for x in dataloader:\n",
    "    x = x.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        out_teacher = teacher.forward(x)\n",
    "        y_teacher = out_teacher.hidden_states[-1][:, 0, :]\n",
    "\n",
    "    y_student = student.embed(x)\n",
    "\n",
    "    student_embeddings.append(y_student.cpu())\n",
    "    teacher_embeddings.append(y_teacher.cpu())\n",
    "\n",
    "assert len(student_embeddings) == len(teacher_embeddings)\n",
    "\n",
    "student_embeddings = torch.cat(student_embeddings, dim=0)\n",
    "teacher_embeddings = torch.cat(teacher_embeddings, dim=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8623cf1d",
   "metadata": {},
   "source": [
    "Here's where things get really crazy. Let's first find the 128 most expressive dimensions of each embedding matrix. Then, let's find a 2-dimensional manifold of that vector space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e9868b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "pca = PCA(n_components=128)\n",
    "tsne = TSNE(n_components=2)\n",
    "\n",
    "s = student_embeddings.float().numpy()\n",
    "t = teacher_embeddings.float().numpy()\n",
    "\n",
    "s = pca.fit_transform(s)\n",
    "t = pca.fit_transform(t)\n",
    "\n",
    "s = tsne.fit_transform(s)\n",
    "t = tsne.fit_transform(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05882491",
   "metadata": {},
   "source": [
    "Finally, let's plot those manifolds so we can view the differences between the two embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55b9b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "axes[0].scatter(s[:, 0], s[:, 1], s=5, alpha=0.7, color=\"blue\")\n",
    "axes[0].set_title(\"Student embeddings\")\n",
    "\n",
    "axes[1].scatter(t[:, 0], t[:, 1], s=5, alpha=0.7, color=\"orange\")\n",
    "axes[1].set_title(\"Teacher embeddings\")\n",
    "\n",
    "for ax in axes:\n",
    "    ax.set_xlabel(\"x\")\n",
    "    ax.set_ylabel(\"y\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
